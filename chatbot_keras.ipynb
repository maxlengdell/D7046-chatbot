{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, LSTM, Bidirectional, Embedding, Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filename):\n",
    "    df = pd.read_csv(filename, encoding = \"latin1\", names = [\"Sentence\", \"Intent\"])\n",
    "    print(df.head())\n",
    "    intent = df[\"Intent\"]\n",
    "    unique_intent = list(set(intent))\n",
    "    sentences = list(df[\"Sentence\"])\n",
    "  \n",
    "    return (intent, unique_intent, sentences)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Sentence   Intent\n",
      "0  How many <item> are left?  balance\n",
      "1           Stock of <Item>?  balance\n",
      "2        Do you have <Item>?  balance\n",
      "3         Balance of <Item>?  balance\n",
      "4           Any <Item> left?  balance\n"
     ]
    }
   ],
   "source": [
    "intent, unique_intent, sentences = load_dataset(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['How many <item> are left?', 'Stock of <Item>?', 'Do you have <Item>?', 'Balance of <Item>?', 'Any <Item> left?']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/maxlengdell/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/maxlengdell/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define stemmer\n",
    "stemmer = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(sentences):\n",
    "    words = []\n",
    "    for s in sentences:\n",
    "        clean = re.sub(r'[^ a-z A-Z 0-9]', \" \", s)\n",
    "        w = word_tokenize(clean)\n",
    "        #stemming\n",
    "        words.append([i.lower() for i in w])\n",
    "    \n",
    "    return words  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118\n",
      "[['how', 'many', 'item', 'are', 'left'], ['stock', 'of', 'item']]\n"
     ]
    }
   ],
   "source": [
    "cleaned_words = cleaning(sentences)\n",
    "print(len(cleaned_words))\n",
    "print(cleaned_words[:2])  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tokenizer(words, filters = '!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~'):\n",
    "    token = Tokenizer(filters = filters)\n",
    "    token.fit_on_texts(words)\n",
    "    print(token)\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_length(words):\n",
    "    return(len(max(words, key = len)))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras_preprocessing.text.Tokenizer object at 0x7ff7b03aa278>\n",
      "Vocab Size = 82 and Maximum length = 9\n"
     ]
    }
   ],
   "source": [
    "word_tokenizer = create_tokenizer(cleaned_words)\n",
    "vocab_size = len(word_tokenizer.word_index) + 1\n",
    "max_length = max_length(cleaned_words)\n",
    "\n",
    "print(\"Vocab Size = %d and Maximum length = %d\" % (vocab_size, max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_doc(token, words):\n",
    "    return(token.texts_to_sequences(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_doc = encoding_doc(word_tokenizer, cleaned_words)\n",
    "#print(encoded_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_doc(encoded_doc, max_length):\n",
    "    return(pad_sequences(encoded_doc, maxlen = max_length, padding = \"post\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_doc = padding_doc(encoded_doc, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3, 22,  1,  7, 13,  0,  0,  0,  0],\n",
       "       [ 9,  4,  1,  0,  0,  0,  0,  0,  0],\n",
       "       [14,  2, 28,  1,  0,  0,  0,  0,  0],\n",
       "       [34,  4,  1,  0,  0,  0,  0,  0,  0],\n",
       "       [29,  1, 13,  0,  0,  0,  0,  0,  0]], dtype=int32)"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_doc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of padded docs =  (118, 9)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of padded docs = \",padded_doc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras_preprocessing.text.Tokenizer object at 0x7ff7b03aae80>\n"
     ]
    }
   ],
   "source": [
    "#tokenizer with filter changed\n",
    "output_tokenizer = create_tokenizer(unique_intent, filters = '!\"#$%&()*+,-/:;<=>?@[\\]^`{|}~')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'price': 1, 'common': 2, 'order': 3, 'balance': 4}"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_output = encoding_doc(output_tokenizer, intent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_output = np.array(encoded_output).reshape(len(encoded_output), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118, 1)"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(encode):\n",
    "    o = OneHotEncoder(sparse = False)\n",
    "    return(o.fit_transform(encode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_one_hot = one_hot(encoded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118, 4)"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, val_X, train_Y, val_Y = train_test_split(padded_doc, output_one_hot, shuffle = True, test_size = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_X = (94, 9) and train_Y = (94, 4)\n",
      "Shape of val_X = (24, 9) and val_Y = (24, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of train_X = %s and train_Y = %s\" % (train_X.shape, train_Y.shape))\n",
    "print(\"Shape of val_X = %s and val_Y = %s\" % (val_X.shape, val_Y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(vocab_size, max_length):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 128, input_length = max_length, trainable = True))\n",
    "    model.add(Bidirectional(LSTM(128)))\n",
    "#   model.add(LSTM(128))\n",
    "    model.add(Dense(32, activation = \"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4, activation = \"softmax\"))\n",
    "  \n",
    "    return model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_13 (Embedding)     (None, 9, 128)            10496     \n",
      "_________________________________________________________________\n",
      "bidirectional_13 (Bidirectio (None, 256)               263168    \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 282,020\n",
      "Trainable params: 282,020\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(vocab_size, max_length)\n",
    "\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxlengdell/opt/anaconda3/envs/nnD7046E/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 94 samples, validate on 24 samples\n",
      "Epoch 1/200\n",
      "94/94 [==============================] - 4s 40ms/step - loss: 1.3812 - accuracy: 0.2021 - val_loss: 1.3802 - val_accuracy: 0.2917\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.38022, saving model to model.h5\n",
      "Epoch 2/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.3541 - accuracy: 0.3404 - val_loss: 1.3839 - val_accuracy: 0.2917\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.38022\n",
      "Epoch 3/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.3408 - accuracy: 0.3085 - val_loss: 1.3879 - val_accuracy: 0.2917\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.38022\n",
      "Epoch 4/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.3418 - accuracy: 0.3085 - val_loss: 1.3839 - val_accuracy: 0.2917\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.38022\n",
      "Epoch 5/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.2956 - accuracy: 0.3511 - val_loss: 1.3692 - val_accuracy: 0.2917\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.38022 to 1.36923, saving model to model.h5\n",
      "Epoch 6/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.2772 - accuracy: 0.4255 - val_loss: 1.3433 - val_accuracy: 0.2917\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.36923 to 1.34331, saving model to model.h5\n",
      "Epoch 7/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.2416 - accuracy: 0.4043 - val_loss: 1.2997 - val_accuracy: 0.3750\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.34331 to 1.29974, saving model to model.h5\n",
      "Epoch 8/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.1941 - accuracy: 0.5638 - val_loss: 1.2396 - val_accuracy: 0.4583\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.29974 to 1.23964, saving model to model.h5\n",
      "Epoch 9/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.1289 - accuracy: 0.5957 - val_loss: 1.1662 - val_accuracy: 0.4583\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.23964 to 1.16619, saving model to model.h5\n",
      "Epoch 10/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.0138 - accuracy: 0.6277 - val_loss: 1.0931 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.16619 to 1.09313, saving model to model.h5\n",
      "Epoch 11/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.9651 - accuracy: 0.6383 - val_loss: 0.9764 - val_accuracy: 0.5833\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.09313 to 0.97642, saving model to model.h5\n",
      "Epoch 12/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.8108 - accuracy: 0.7766 - val_loss: 0.9016 - val_accuracy: 0.6250\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.97642 to 0.90163, saving model to model.h5\n",
      "Epoch 13/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6618 - accuracy: 0.7872 - val_loss: 0.8365 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.90163 to 0.83650, saving model to model.h5\n",
      "Epoch 14/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5342 - accuracy: 0.8298 - val_loss: 0.7792 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.83650 to 0.77925, saving model to model.h5\n",
      "Epoch 15/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.8085 - val_loss: 0.7521 - val_accuracy: 0.7917\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.77925 to 0.75210, saving model to model.h5\n",
      "Epoch 16/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.3565 - accuracy: 0.8298 - val_loss: 0.7051 - val_accuracy: 0.7917\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.75210 to 0.70511, saving model to model.h5\n",
      "Epoch 17/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2808 - accuracy: 0.9043 - val_loss: 0.7366 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.70511\n",
      "Epoch 18/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.2274 - accuracy: 0.9255 - val_loss: 0.7126 - val_accuracy: 0.7917\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.70511\n",
      "Epoch 19/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2209 - accuracy: 0.8830 - val_loss: 0.6522 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.70511 to 0.65216, saving model to model.h5\n",
      "Epoch 20/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1831 - accuracy: 0.9255 - val_loss: 0.7964 - val_accuracy: 0.7917\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.65216\n",
      "Epoch 21/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1069 - accuracy: 0.9787 - val_loss: 0.9652 - val_accuracy: 0.7917\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.65216\n",
      "Epoch 22/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1951 - accuracy: 0.9468 - val_loss: 0.6402 - val_accuracy: 0.7917\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.65216 to 0.64023, saving model to model.h5\n",
      "Epoch 23/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1474 - accuracy: 0.9362 - val_loss: 0.7119 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.64023\n",
      "Epoch 24/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1421 - accuracy: 0.9362 - val_loss: 0.5838 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.64023 to 0.58379, saving model to model.h5\n",
      "Epoch 25/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0757 - accuracy: 0.9787 - val_loss: 0.6793 - val_accuracy: 0.7917\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.58379\n",
      "Epoch 26/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0894 - accuracy: 0.9681 - val_loss: 0.6271 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.58379\n",
      "Epoch 27/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1076 - accuracy: 0.9681 - val_loss: 0.7672 - val_accuracy: 0.7917\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.58379\n",
      "Epoch 28/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0592 - accuracy: 0.9787 - val_loss: 0.9079 - val_accuracy: 0.7917\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.58379\n",
      "Epoch 29/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0680 - accuracy: 0.9894 - val_loss: 0.9468 - val_accuracy: 0.7917\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.58379\n",
      "Epoch 30/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.9894 - val_loss: 0.9089 - val_accuracy: 0.7917\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.58379\n",
      "Epoch 31/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0553 - accuracy: 0.9787 - val_loss: 0.8391 - val_accuracy: 0.7917\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.58379\n",
      "Epoch 32/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0429 - accuracy: 0.9894 - val_loss: 0.7614 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.58379\n",
      "Epoch 33/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0512 - accuracy: 0.9681 - val_loss: 0.6851 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.58379\n",
      "Epoch 34/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0250 - accuracy: 1.0000 - val_loss: 0.6177 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.58379\n",
      "Epoch 35/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 0.5674 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.58379 to 0.56742, saving model to model.h5\n",
      "Epoch 36/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0379 - accuracy: 0.9894 - val_loss: 0.5683 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.56742\n",
      "Epoch 37/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0380 - accuracy: 0.9894 - val_loss: 0.5540 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.56742 to 0.55402, saving model to model.h5\n",
      "Epoch 38/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0180 - accuracy: 0.9894 - val_loss: 0.5480 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.55402 to 0.54797, saving model to model.h5\n",
      "Epoch 39/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0711 - accuracy: 0.9681 - val_loss: 0.5609 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.54797\n",
      "Epoch 40/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0356 - accuracy: 0.9787 - val_loss: 0.5856 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.54797\n",
      "Epoch 41/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0255 - accuracy: 0.9894 - val_loss: 0.5875 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.54797\n",
      "Epoch 42/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0236 - accuracy: 0.9894 - val_loss: 0.5826 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.54797\n",
      "Epoch 43/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0180 - accuracy: 0.9894 - val_loss: 0.5709 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.54797\n",
      "Epoch 44/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0355 - accuracy: 1.0000 - val_loss: 0.5611 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.54797\n",
      "Epoch 45/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.5587 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.54797\n",
      "Epoch 46/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.5599 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.54797\n",
      "Epoch 47/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 0.5756 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.54797\n",
      "Epoch 48/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0292 - accuracy: 0.9894 - val_loss: 0.5914 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.54797\n",
      "Epoch 49/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.6137 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.54797\n",
      "Epoch 50/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.6396 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.54797\n",
      "Epoch 51/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0230 - accuracy: 0.9894 - val_loss: 0.6516 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.54797\n",
      "Epoch 52/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.6512 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.54797\n",
      "Epoch 53/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.6648 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.54797\n",
      "Epoch 54/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0273 - accuracy: 1.0000 - val_loss: 0.6750 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.54797\n",
      "Epoch 55/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0169 - accuracy: 0.9894 - val_loss: 0.6752 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.54797\n",
      "Epoch 56/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.6798 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.54797\n",
      "Epoch 57/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0352 - accuracy: 1.0000 - val_loss: 0.6711 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.54797\n",
      "Epoch 58/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.6613 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.54797\n",
      "Epoch 59/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.6582 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.54797\n",
      "Epoch 60/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.6531 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.54797\n",
      "Epoch 61/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.6543 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.54797\n",
      "Epoch 62/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.6595 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.54797\n",
      "Epoch 63/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.6666 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.54797\n",
      "Epoch 64/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.6716 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.54797\n",
      "Epoch 65/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.6710 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.54797\n",
      "Epoch 66/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.6674 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.54797\n",
      "Epoch 67/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.6705 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.54797\n",
      "Epoch 68/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6788 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.54797\n",
      "Epoch 69/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6874 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.54797\n",
      "Epoch 70/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0449 - accuracy: 0.9681 - val_loss: 0.6999 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.54797\n",
      "Epoch 71/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0178 - accuracy: 0.9894 - val_loss: 0.7199 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.54797\n",
      "Epoch 72/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.7361 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.54797\n",
      "Epoch 73/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0292 - accuracy: 0.9787 - val_loss: 0.7210 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.54797\n",
      "Epoch 74/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.6832 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.54797\n",
      "Epoch 75/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0297 - accuracy: 0.9894 - val_loss: 0.6434 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.54797\n",
      "Epoch 76/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.6345 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.54797\n",
      "Epoch 77/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0137 - accuracy: 0.9894 - val_loss: 0.6398 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.54797\n",
      "Epoch 78/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0230 - accuracy: 0.9894 - val_loss: 0.6485 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.54797\n",
      "Epoch 79/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.6564 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.54797\n",
      "Epoch 80/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.6603 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.54797\n",
      "Epoch 81/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0187 - accuracy: 0.9894 - val_loss: 0.6594 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.54797\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.6485 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.54797\n",
      "Epoch 83/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0311 - accuracy: 0.9894 - val_loss: 0.6448 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.54797\n",
      "Epoch 84/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.6448 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.54797\n",
      "Epoch 85/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.6419 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.54797\n",
      "Epoch 86/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0253 - accuracy: 0.9894 - val_loss: 0.6438 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.54797\n",
      "Epoch 87/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0145 - accuracy: 0.9894 - val_loss: 0.6482 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.54797\n",
      "Epoch 88/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.6518 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.54797\n",
      "Epoch 89/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.6756 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.54797\n",
      "Epoch 90/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.6943 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.54797\n",
      "Epoch 91/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.7108 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.54797\n",
      "Epoch 92/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.7254 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.54797\n",
      "Epoch 93/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0337 - accuracy: 0.9787 - val_loss: 0.7232 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.54797\n",
      "Epoch 94/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.7009 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.54797\n",
      "Epoch 95/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0170 - accuracy: 0.9894 - val_loss: 0.6919 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.54797\n",
      "Epoch 96/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.6862 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.54797\n",
      "Epoch 97/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.6905 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.54797\n",
      "Epoch 98/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0160 - accuracy: 0.9894 - val_loss: 0.7089 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.54797\n",
      "Epoch 99/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.7400 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.54797\n",
      "Epoch 100/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.7705 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.54797\n",
      "Epoch 101/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.7960 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.54797\n",
      "Epoch 102/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.8212 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.54797\n",
      "Epoch 103/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8349 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.54797\n",
      "Epoch 104/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0187 - accuracy: 0.9894 - val_loss: 0.8549 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.54797\n",
      "Epoch 105/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0206 - accuracy: 0.9894 - val_loss: 0.8822 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.54797\n",
      "Epoch 106/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.9086 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.54797\n",
      "Epoch 107/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.9299 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.54797\n",
      "Epoch 108/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.9541 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.54797\n",
      "Epoch 109/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.9826 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.54797\n",
      "Epoch 110/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0162 - accuracy: 0.9894 - val_loss: 1.0430 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.54797\n",
      "Epoch 111/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.0871 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.54797\n",
      "Epoch 112/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.1168 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.54797\n",
      "Epoch 113/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.1186 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.54797\n",
      "Epoch 114/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 1.1055 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.54797\n",
      "Epoch 115/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.0946 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.54797\n",
      "Epoch 116/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 7.1193e-04 - accuracy: 1.0000 - val_loss: 1.0896 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.54797\n",
      "Epoch 117/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 1.1115 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.54797\n",
      "Epoch 118/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.1711 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.54797\n",
      "Epoch 119/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.2035 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.54797\n",
      "Epoch 120/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.1777 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.54797\n",
      "Epoch 121/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0220 - accuracy: 0.9894 - val_loss: 1.0487 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.54797\n",
      "Epoch 122/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.9428 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.54797\n",
      "Epoch 123/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0157 - accuracy: 0.9894 - val_loss: 0.8927 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.54797\n",
      "Epoch 124/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.8652 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.54797\n",
      "Epoch 125/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0203 - accuracy: 0.9894 - val_loss: 0.8137 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.54797\n",
      "Epoch 126/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.7598 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.54797\n",
      "Epoch 127/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.6872 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.54797\n",
      "Epoch 128/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 8.3199e-04 - accuracy: 1.0000 - val_loss: 0.6040 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.54797\n",
      "Epoch 129/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.5626 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.54797\n",
      "Epoch 130/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5743 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.54797\n",
      "Epoch 131/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0133 - accuracy: 0.9894 - val_loss: 0.9460 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.54797\n",
      "Epoch 132/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0240 - accuracy: 0.9894 - val_loss: 1.2199 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.54797\n",
      "Epoch 133/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.1973 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.54797\n",
      "Epoch 134/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0285 - accuracy: 0.9894 - val_loss: 1.1678 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.54797\n",
      "Epoch 135/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0272 - accuracy: 0.9894 - val_loss: 1.0353 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.54797\n",
      "Epoch 136/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0119 - accuracy: 0.9894 - val_loss: 0.8524 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.54797\n",
      "Epoch 137/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0120 - accuracy: 0.9894 - val_loss: 0.7938 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.54797\n",
      "Epoch 138/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0217 - accuracy: 0.9894 - val_loss: 0.7486 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.54797\n",
      "Epoch 139/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0145 - accuracy: 0.9894 - val_loss: 0.7469 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.54797\n",
      "Epoch 140/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0219 - accuracy: 0.9894 - val_loss: 0.7518 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.54797\n",
      "Epoch 141/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0305 - accuracy: 0.9894 - val_loss: 0.7146 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.54797\n",
      "Epoch 142/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.6592 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.54797\n",
      "Epoch 143/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.6977 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.54797\n",
      "Epoch 144/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 9.7769e-04 - accuracy: 1.0000 - val_loss: 0.7525 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.54797\n",
      "Epoch 145/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0804 - accuracy: 0.9787 - val_loss: 0.5933 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.54797\n",
      "Epoch 146/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2220 - accuracy: 0.9574 - val_loss: 0.8068 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.54797\n",
      "Epoch 147/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2577 - accuracy: 0.9681 - val_loss: 0.9108 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.54797\n",
      "Epoch 148/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.2370 - val_accuracy: 0.7917\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.54797\n",
      "Epoch 149/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3582 - accuracy: 0.9468 - val_loss: 1.2983 - val_accuracy: 0.7917\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.54797\n",
      "Epoch 150/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 1.3459 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.54797\n",
      "Epoch 151/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0452 - accuracy: 0.9681 - val_loss: 1.0903 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.54797\n",
      "Epoch 152/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0527 - accuracy: 0.9787 - val_loss: 0.7172 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.54797\n",
      "Epoch 153/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.6858 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.54797\n",
      "Epoch 154/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 0.7165 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.54797\n",
      "Epoch 155/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.8066 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.54797\n",
      "Epoch 156/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.9060 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.54797\n",
      "Epoch 157/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.9795 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.54797\n",
      "Epoch 158/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 1.0610 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.54797\n",
      "Epoch 159/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0245 - accuracy: 0.9894 - val_loss: 1.1029 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.54797\n",
      "Epoch 160/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 1.1869 - val_accuracy: 0.7917\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.54797\n",
      "Epoch 161/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.2335 - val_accuracy: 0.7917\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.54797\n",
      "Epoch 162/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.2491 - val_accuracy: 0.7917\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.54797\n",
      "Epoch 163/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0218 - accuracy: 0.9894 - val_loss: 1.2463 - val_accuracy: 0.7917\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.54797\n",
      "Epoch 164/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.2325 - val_accuracy: 0.7917\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.54797\n",
      "Epoch 165/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 1.1995 - val_accuracy: 0.7917\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.54797\n",
      "Epoch 166/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.1691 - val_accuracy: 0.7917\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.54797\n",
      "Epoch 167/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0131 - accuracy: 0.9894 - val_loss: 1.1316 - val_accuracy: 0.7917\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.54797\n",
      "Epoch 168/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0136 - accuracy: 0.9894 - val_loss: 1.1083 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.54797\n",
      "Epoch 169/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.0932 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.54797\n",
      "Epoch 170/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.0844 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.54797\n",
      "Epoch 171/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.0738 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.54797\n",
      "Epoch 172/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.0637 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.54797\n",
      "Epoch 173/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0184 - accuracy: 0.9894 - val_loss: 1.0525 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.54797\n",
      "Epoch 174/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 1.0472 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.54797\n",
      "Epoch 175/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.0487 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.54797\n",
      "Epoch 176/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.0555 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.54797\n",
      "Epoch 177/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0143 - accuracy: 0.9894 - val_loss: 1.0784 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.54797\n",
      "Epoch 178/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.1017 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.54797\n",
      "Epoch 179/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.1042 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.54797\n",
      "Epoch 180/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 1.0997 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.54797\n",
      "Epoch 181/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.0972 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.54797\n",
      "Epoch 182/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.0970 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.54797\n",
      "Epoch 183/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.0985 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.54797\n",
      "Epoch 184/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0215 - accuracy: 0.9894 - val_loss: 1.1045 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.54797\n",
      "Epoch 185/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.1134 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.54797\n",
      "Epoch 186/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.1258 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.54797\n",
      "Epoch 187/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0273 - accuracy: 0.9787 - val_loss: 1.1334 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.54797\n",
      "Epoch 188/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0147 - accuracy: 0.9894 - val_loss: 1.1335 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.54797\n",
      "Epoch 189/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 1.1338 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.54797\n",
      "Epoch 190/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.1398 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.54797\n",
      "Epoch 191/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 1.1513 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.54797\n",
      "Epoch 192/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0141 - accuracy: 0.9894 - val_loss: 1.1584 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.54797\n",
      "Epoch 193/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.1625 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.54797\n",
      "Epoch 194/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.1678 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.54797\n",
      "Epoch 195/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 1.1744 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.54797\n",
      "Epoch 196/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0212 - accuracy: 0.9787 - val_loss: 1.1918 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.54797\n",
      "Epoch 197/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0167 - accuracy: 0.9894 - val_loss: 1.2178 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.54797\n",
      "Epoch 198/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.2383 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.54797\n",
      "Epoch 199/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 1.2552 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.54797\n",
      "Epoch 200/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.2700 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.54797\n"
     ]
    }
   ],
   "source": [
    "filename = 'model.h5'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "history = model.fit(train_X, train_Y, epochs = 200, batch_size = 32, validation_data = (val_X, val_Y), callbacks = [checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    " model = load_model(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(text):\n",
    "    clean = re.sub(r'[^ a-z A-Z 0-9]', \" \", text)\n",
    "    test_word = word_tokenize(clean)\n",
    "    test_word = [w.lower() for w in test_word]\n",
    "    test_ls = word_tokenizer.texts_to_sequences(test_word)\n",
    "    print(test_word)\n",
    "    #Check for unknown words\n",
    "    if [] in test_ls:\n",
    "        test_ls = list(filter(None, test_ls))\n",
    "    \n",
    "    test_ls = np.array(test_ls).reshape(1, len(test_ls))\n",
    " \n",
    "    x = padding_doc(test_ls, max_length)\n",
    "  \n",
    "    pred = model.predict_proba(x)\n",
    "  \n",
    "  \n",
    "    return pred\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_output(pred, classes):\n",
    "    predictions = pred[0]\n",
    " \n",
    "    classes = np.array(classes)\n",
    "    ids = np.argsort(-predictions)\n",
    "    classes = classes[ids]\n",
    "    predictions = -np.sort(-predictions)\n",
    " \n",
    "    for i in range(pred.shape[1]):\n",
    "        print(\"%s has confidence = %s\" % (classes[i], (predictions[i])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['how', 'much', 'does', 'it', 'cost']\n",
      "price has confidence = 0.9985795\n",
      "order has confidence = 0.0012719035\n",
      "common has confidence = 0.00012882218\n",
      "balance has confidence = 1.9682106e-05\n"
     ]
    }
   ],
   "source": [
    "#Price\n",
    "text = \"How much does it cost?\"\n",
    "pred = predictions(text)\n",
    "get_final_output(pred, unique_intent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['how', 'many', 'item', 'are', 'in', 'stock']\n",
      "balance has confidence = 0.93519163\n",
      "order has confidence = 0.054477524\n",
      "common has confidence = 0.00944595\n",
      "price has confidence = 0.00088483363\n"
     ]
    }
   ],
   "source": [
    "#Balance\n",
    "text = \"how many pants are in stock?\"\n",
    "pred = predictions(text)\n",
    "get_final_output(pred, unique_intent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'want', 'to', 'buy', '3', 'pants']\n",
      "order has confidence = 0.92502147\n",
      "balance has confidence = 0.046053883\n",
      "price has confidence = 0.025238369\n",
      "common has confidence = 0.003686244\n"
     ]
    }
   ],
   "source": [
    "#Order\n",
    "text = \"I want to buy 3 pants\"\n",
    "pred = predictions(text)\n",
    "get_final_output(pred, unique_intent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'need', 'help']\n",
      "common has confidence = 0.95201236\n",
      "balance has confidence = 0.03581892\n",
      "price has confidence = 0.008233834\n",
      "order has confidence = 0.0039348374\n"
     ]
    }
   ],
   "source": [
    "#Common\n",
    "text = \"I need help\"\n",
    "pred = predictions(text)\n",
    "get_final_output(pred, unique_intent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "opening_lines = ['Hello, what can I help you with?',\n",
    "                'How can I help you?',\n",
    "                'Whats on your mind today?']\n",
    "\n",
    "def randomOpening():\n",
    "    index = random.randint(0,len(opening_lines)-1)\n",
    "    print(opening_lines[index])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, what can I help you with?\n"
     ]
    }
   ],
   "source": [
    "def cli():\n",
    "    while True:\n",
    "        randomOpening()\n",
    "        user_input = input(\"Ask the chatbot something: \")\n",
    "        print(user_input)\n",
    "        if(user_input==\"quit\"):\n",
    "            break\n",
    "        else:\n",
    "            pred = predictions(user_input)\n",
    "            print(pred)\n",
    "            get_final_output(pred, unique_intent)\n",
    "\n",
    "        \n",
    "cli()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
